{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treshold Handling in Extreme multi-label classification (XMLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulaire :\n",
    "- extreme multi-label classification (XMLC)\n",
    "- Probability Label trees (PLT)\n",
    "- sparse probability estimates (SPEs)\n",
    "- Sorting-based threshold optimization (STO)\n",
    "- online F-measure optimization (OFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Présentation du sujet\n",
    "\n",
    "Ce que nous allons étudier dans ce notebook est la multi-classification de données dans un très grand nombre de classes : **Extreme multi-label classification (XMLC)**. Pour chaque instance (ligne) du dataset, l'objectif est d'identifier les différentes catégories/labels de l'instance. Ceci peut être appliqué par exemple à la classification d'images : pour chaque image (instance), l'objectif est d'identifier les différents éléments (labels) présents sur une photo. Y-a-t-il une table sur la photo (Oui ou Non), une chaise (Oui ou Non), un chat (Oui ou Non), un nuages(Oui ou Non) etc... Les différents labels possibles sont parfois très nombreux : des centaines de milliers voire des millions !\n",
    "\n",
    "L'enjeu est d'arriver à prédire les labels de chacunes de données au mieux, tout en ayant un complexité d'éxécution raisonnable. Ceci n'est pas évident, surtout si les datasets sont très importants. Avec un dataset de $10^4$ instances, et avec $10^6$ labels à prédire, cela fait $10^{10}$ prédictions à réaliser et potentiellement stoquer ! Nous allons essayer de comprendre comment on peut affronter ce problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>Les idées et algorithmes présentés dans ce notebook sont en grande partie tirées de l'article :\n",
    "\n",
    "**Extreme F-Measure Maximisation using Sparse Probability Estimates**, <br>Jasinska, Dembcynski, Busa-Fekete, Pfannschmidt, Klerx, Hullermeier - 2016 <br>\n",
    "http://proceedings.mlr.press/v48/jasinska16.pdf\n",
    "\n",
    "D'autre articles ont également été utilisés pour la compréhension : \n",
    "\n",
    "**Probabilistic Label Trees for Extreme Multi-label Classification**, <br> Kalina Jasinska-Kobus, Marek Wydmuch, Krzysztof Dembczyński, Mikhail Kuznetsov, and Róbert Busa-Fekete <br>\n",
    "https://arxiv.org/pdf/2009.11218.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Formalisation du problème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instances, labels, prédiction : \n",
    "Nous nous intéressons à un problème de XMLC avec **m labels**. La particularité de notre étude est que ce nombre m est très grand.<br> Chaque instance se se note sous forme de vecteur : $\\mathbf{x_i}$. Notre dataset contient n instances.<br>\n",
    "L'information d'appartenance de l'instance $\\mathbf{x_i}$ aux différentes catégories est contenue dans le vecteur $\\mathbf{y_i}  = (y_{i,1}, ... , y_{i,m}) \\in \\{0,1\\}^m$. Si $y_{i,j} = 1$, cela signifie que l'instance $\\mathbf{x_i}$ est \"labélisé\" $j$. <br>\n",
    "Notre dataset se note donc : $ \\mathcal{D} = \\{(\\mathbf{x_i}, \\mathbf{y_i})\\}_{i=1}^n$ <br>\n",
    "\n",
    "\n",
    "On peut également définir la matrice de taille $ n \\times m$ contenant toutes les informations de labels du dataset : $\\mathbf{Y} = (\\mathbf{y_{1}}, ... , \\mathbf{y_{n}})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifieurs :\n",
    "\n",
    "Les classifieurs seront les modèles permettant de prédire les labels des données. Les prédictions de labels d'une instance i de ces classifieurs seront contenues dans le vecteur : $ \\mathbf{\\hat{y_i}}  = (\\hat{y_{i,1}}, ... , \\hat{y_{i,m}}) \\in \\{0,1\\}^m $. <br>\n",
    "De même que qu'au dessus, nous pouvons définir la matrice de prédiction de taille $ n \\times m$ du dataset : $\\mathbf{\\hat{Y}} = (\\mathbf{\\hat{y}_{1}}, ... , \\mathbf{\\hat{y}_{n}})$ <br>\n",
    "\n",
    "Soit $\\eta(\\mathbf{x},j)$,  la probabilité que le label j de l'instance **x** soit positive : $\\eta(\\mathbf{x},j) = \\mathbf{P}(y_j=1 \\vert \\mathbf{x})$. <br>\n",
    "\n",
    "Dans notre étude nous allons nous intéresser à des classifieurs probabilistiques : ils vont estimer ces probabilités  $\\eta(\\mathbf{x},j)$ <br>\n",
    "\n",
    "A partir d'une donnée **x**, les classifieurs probabilistiques estiment les probabilités  $\\eta(\\mathbf{x},j)$ : on note les résultats ainsi obtenus par les classifieurs: $\\hat{\\eta}(\\mathbf{x},j)$ <br>\n",
    "$$\\hat{\\eta} : \\chi \\times [ m ]  \\rightarrow [0,1]$$ <br>\n",
    "\n",
    "Une fois que les classfieurs ont permis d'obtenir ces valeurs $\\eta$, il reste à définir les **thresholds** $\\mathbf{\\tau}$, qui définissent les valeurs minimales que les $\\hat{\\eta}$ doivent dépasser pour assigner les labels aux instances. <br>\n",
    "Ainsi, on définit : $\\mathbf{\\tau} = [\\tau_1, ... \\tau_m]$ tels que pour tout label j et instance **x** :\n",
    "\n",
    "$$ \\hat{y}_{i,j} =  \\left\\{\\begin{array}{ll} 0 & \\textrm{si } \\hat{\\eta}(\\mathbf{x_i},j) > \\tau_j  \\\\ 1 & \\textrm{sinon}\\end{array}\\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrique à maximiser : la F-measure :\n",
    "\n",
    "Dans notre étude, nous souhaitons avoir le plus possible de prédictions justes. Pour cela la métrique que nous allons utiliser est la F-measure :\n",
    "\n",
    "\\begin{align*}\n",
    "F_M (\\mathbf{Y}, \\mathbf{\\hat{Y}}) & = \\frac{1}{m} \\sum_{j=1}^m F_s(\\mathbf{Y}.j, \\mathbf{\\hat{Y}}.j)\\\\\n",
    "& = \\frac{1}{m} \\sum_{j=1}^m  \\frac{2 \\sum_{i=1}^n y_{i,j}\\hat{y}_{i,j}}{\\sum_{i=1}^n y_{i,j} + \\sum_{i=1}^n \\hat{y}_{i,j}}\n",
    "\\end{align*}\n",
    "\n",
    "$\\mathbf{Y}.j$ et $\\mathbf{\\hat{Y}}.j$ sont les colonnes j des matrices respectives $\\mathbf{Y}$ et $\\mathbf{\\hat{Y}}$. <br>\n",
    "$F_M$ est la F-measure Macro (ou F-score) de toutes nos prédictions : elle concerne tous les labels $F_s$. Elle est la moyenne des F-measure standard. La F-measure standard est spécifiques à un label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour revenir sur les trasholds $\\tau_j$, l'objectif est est donc de trouver : \n",
    "$$ \\mathbf{\\tau^*} = \\underset{\\mathbf{\\tau} \\in [0,1]^m}{\\operatorname{argmax}} F(\\mathbf{\\tau}, \\mathbf{\\hat{\\eta}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentons la F_measure standard sur un exemple simple : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard F-measure pour un prédiction parfaite (4/4)  1.0\n",
      "\n",
      "\n",
      "Standard F-measure pour un prédiction très mauvaise (0/4) :  0.0\n",
      "\n",
      "\n",
      "Standard F-measure pour un prédiction intermédiaire (3/4):  0.8\n"
     ]
    }
   ],
   "source": [
    "def F_measure_standard(y,y_hat):\n",
    "    if (np.sum(y)+np.sum(y_hat)) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return 2*np.dot(y,y_hat.T)/(np.sum(y)+np.sum(y_hat))\n",
    "### Complexité : n\n",
    "\n",
    "y = np.array([1,0,0,1])\n",
    "y_hat = np.array([1,0,0,1])\n",
    "print('Standard F-measure pour un prédiction parfaite (4/4) ', F_measure_standard(y, y_hat))\n",
    "print('\\n')\n",
    "y = np.array([1,0,0,1])\n",
    "y_hat = np.array([0,1,1,0])\n",
    "print('Standard F-measure pour un prédiction très mauvaise (0/4) : ', F_measure_standard(y, y_hat))\n",
    "print('\\n')\n",
    "y = np.array([1,0,0,1])\n",
    "y_hat = np.array([1,1,0,1])\n",
    "print('Standard F-measure pour un prédiction intermédiaire (3/4): ', F_measure_standard(y, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La F-measure standard varie entre 0 et 1.<br>\n",
    "0 correspond à un prédiction très mauvaise, et 1 correspond à une prédiction parfaite. \n",
    "\n",
    "La F-measure Macro étant la moyenne de toutes les F-measures standard pour chaque label, elle possède les même propriétés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y :\n",
      " [[1 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 0]]\n",
      "\n",
      "Y_hat :\n",
      " [[1 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]]\n",
      "\n",
      "Nombre d'instances :  4\n",
      "Nombre de labels :  2 \n",
      "\n",
      "Macro F-measure : 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "def F_measure_macro(Y, Y_hat):\n",
    "    nb_labels = len(Y[0])\n",
    "    result = 0\n",
    "    nb_no_result = 0\n",
    "    for j in range(nb_labels):\n",
    "        y = Y[:,j]\n",
    "        y_hat = Y_hat[:,j]\n",
    "        res = F_measure_standard(y,y_hat)\n",
    "        if res :\n",
    "            result = result +  res\n",
    "        else:\n",
    "            nb_no_result += 1\n",
    "#         print('Standard F-measure of label ' + str(j) + ' : ', res)\n",
    "    if nb_labels-nb_no_result >0:\n",
    "        return (result/(nb_labels-nb_no_result))\n",
    "    else :\n",
    "        return 1\n",
    "### Complexité : n x m\n",
    "\n",
    "Y = np.array([[1,0],[0,1],[0,0],[1,0]])\n",
    "print('Y :\\n', Y)\n",
    "Y_hat = np.array([[1,0],[0,1],[0,0],[1,1]])\n",
    "print('\\nY_hat :\\n', Y_hat)\n",
    "print(\"\\nNombre d'instances : \", len(Y))\n",
    "print(\"Nombre de labels : \", len(Y[0]), '\\n')\n",
    "print('Macro F-measure :', F_measure_macro(Y, Y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notre objectif sera de maximiser la Macro F-measure.** Cela revient à maximiser chaque Standard F-measure de chaque label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - Présentation du dataset utilisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser le dataset **eurlex-4k** qui est issue d'un concours Kaggle (https://www.kaggle.com/c/extreme-classification-eurlex/data?select=EURLex-4K.zip).<br>\n",
    "Ces données ont été reprises dans ce GitHub (https://github.com/mwydmuch/napkinXC) dans lequel est crée la libraire napkinXC qui crée des models de prédictions pour des datasets avec un nombre de classes très élevé. <br>\n",
    "Ce dataset (un peu abstrait) contient 4000 labels. <br>\n",
    "Nous allons donc utiliser la librairie napkinXC pour charger les données.\n",
    "\n",
    "Ce chargement des données se fait dans le fichier python load_data_napkinxc.py, car quelques pré-traitements inutiles à la compréhension de l'étude y sont fait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data_napkinxc import X_train_napxinxc, Y_train_napxinxc, X_test_napxinxc, Y_test_napxinxc # Array dans un format particulier spécifique à npakinxc \n",
    "from load_data_napkinxc import X_train_arr_tot, X_test_arr_tot, Y_train_arr_tot, Y_test_arr_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train :  (15539, 5000)\n",
      "[[0.084556 0.138594 0.094304 ... 0.       0.       0.      ]\n",
      " [0.050734 0.762265 0.754431 ... 0.       0.       0.      ]\n",
      " [0.101468 0.138594 0.377215 ... 0.       0.       0.      ]\n",
      " ...\n",
      " [0.050734 0.346484 0.188608 ... 0.       0.       0.      ]\n",
      " [0.084556 2.39074  0.848735 ... 0.       0.       0.      ]\n",
      " [0.084556 0.20789  0.282912 ... 0.       0.       0.      ]]\n"
     ]
    }
   ],
   "source": [
    "print('Shape X_train : ', (X_train_arr_tot).shape)\n",
    "print(X_train_arr_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_arr_tot est donc une matrice contenant les informations de X du dataset. Nous avons donc 15539 instance avec chacunes 5000 features qui sont des floats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Y_train :  (15539, 3993)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Shape Y_train : ', Y_train_arr_tot.shape)\n",
    "print(Y_train_arr_tot)\n",
    "# print('Y_train item example : ', Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_train_arr_tot est également un matrice contenant les informations de label de chaque instance. L'élément i,j de cette matrices sera de 1 si l'instance $\\mathbf{x_i}$ est labélisée j, et 0 sinon.\n",
    "\n",
    "On voit comme l'indique le nom du dataset l'indique (eurlex-4k) qu'il y a environ 4000 labels (3993) dans ce dataset.\n",
    "\n",
    "\n",
    "Regardons les labels d'une instance : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 446,  521, 1149, 1249, 1265, 1482]),)\n"
     ]
    }
   ],
   "source": [
    "def lab_of_instance(y_arr, label):\n",
    "    return np.where(y_arr[label]==1)\n",
    "print(lab_of_instance(Y_train_arr_tot, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'instance 0 possède ainsi les labels 446, 521, 149, 1249, 1265 et 1482."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la suite, nous utiliserons parfois seulement une partie (3500 instances) de ce dataset afin d'avoir des temps d'éxécution plus courts. C'est pourquoi nous définissons le variables suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr = X_train_arr_tot[:3500,:]\n",
    "Y_train_arr = Y_train_arr_tot[:3500,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-success\", style=\"font-size:17px;\">\n",
    "\n",
    "Nous allons maintenant nous intéresser à la construction des classifieurs. Dans cette étude elle se déroule en 2 étapes : <br>\n",
    "<ol>\n",
    "<li style=\"font-weight:bold ;\"> Etape 1 : Contrsuire le meilleur estimateur des $\\eta$.\n",
    "<li style=\"font-weight:bold ;\"> Etape 2 : Trouver les meilleurs thresholds $\\tau$ pour passer de $\\hat{\\eta}$ à y.\n",
    "</ol>\n",
    "    \n",
    "Dans ce notebook, nous allons parler rapidement de la première partie, puis nous allons nous concentrer sur la deuxième partie\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV - Etape 1 : Création des modèles pour obtenir les estimateurs $\\hat{\\eta}$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un estimateur binaire spécifique à un label.\n",
    "Une des solutions possibles pour créer un modèle de prédiction global est de créer un modèle de classification binaire par label.\n",
    "Par exemple, avec notre dataset, on crérait un modèle par colonne (3993).\n",
    "\n",
    "Nous allons ici créer un réseau de neuronnes très simple s'entrainant avec une loss binary crossentropy sur un label de notre dataset. Nous noterons par la suite ce label (ou la colonne correspondante) **j**. Ce modèle renvoit pour chaque instance la probabilité que cette instance soit \"labélisée\" j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Création du modèle\n",
    "def train_NN_model_specific_label(label, x_train, y_train):\n",
    "    t = time.time()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=5000, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    # Entrainement du modèle\n",
    "    model.fit(x_train, y_train[:,label], epochs=2, verbose=0)\n",
    "    print(\"Temps d'entrainement d'un modèle binaire (secondes): \", time.time()-t)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'entrainement d'un modèle binaire (secondes):  2.64646053314209\n",
      "[2.2637137e-12 2.5284579e-01 1.6443070e-36 ... 1.9969450e-02 0.0000000e+00\n",
      " 6.1115049e-15]\n"
     ]
    }
   ],
   "source": [
    "label = 8 # label pour lequel on crée le modèle\n",
    "model = train_NN_model_specific_label(label, X_train_arr_tot, Y_train_arr_tot) # Création et entrainement du modèle\n",
    "pred_probas_train = model.predict(X_train_arr_tot)[:,0] # Prédictions des eta\n",
    "print(pred_probas_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle nous retourne donc ici le vecteur $\\hat{\\eta}(\\mathbf{X},j) = \\mathbf{P}(y_j=1 \\vert \\mathbf{X})$ avex $\\mathbf{X}$ qui est X_train_arr_tot et j qui est le label considéré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De la prédiction de probabilité à la prédiction :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir savoir si notre modèle est peformant, il faut savoir à partir de quelle valeur de $\\hat{\\eta}(x,j)$ on considère que x est labélisé j. Cette valeur correspond à $\\tau_j$ défini en partie II. \n",
    "\n",
    "On s'attardera la construction lors de l'explication de l'étape 2 en partie V, mais on peut définir pour l'instant un fonction simple qui à partir d'une liste de valeurs de probabilité $\\eta$ de taille n crée une liste de prédiction de taille n spécifique à un label. Cette liste donne pour chaque instance 1 si sa probabilité est au dessus d'un certain threshold $\\tau_j$ et 0 sinon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_from_proba_one_label(proba_list, tresh_label): \n",
    "    prediction = np.zeros(len(proba_list))\n",
    "    for j, p in enumerate(proba_list):\n",
    "        if p>tresh_label:\n",
    "            prediction[j] = 1\n",
    "    return prediction\n",
    "## Complexité  n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction pred_from_proba_one_label est spécifique à un label, on peut aussi créer une fonction qui à partir de la matrice totale de probabilitée, et du vecteur de thresholds $\\mathbf{\\tau}$ qui contient tous les thresholds $\\tau_{j}$ de nos labels, renvoit un grande matrice de prédiction pour notre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_from_proba_all_labels(proba_list, thresh_list): \n",
    "    all_preds = np.zeros(proba_list.shape)\n",
    "    for i in range(proba_list.shape[1]):\n",
    "        all_preds[:,i] = pred_from_proba_one_label(proba_list[:,i], thresh_list[i])\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats pour notre estimateur binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut donc utiliser la fonction pred_from_proba_one_label pour obtenir les prédictions de labels de notre estimateur binaire en prenant arbitrairement comme treshold 0.5 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "predictions = pred_from_proba_one_label(pred_probas_train, 0.5)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant la F-measure standard de ce label : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F measure standard du label 8 :  0.5380116959064327\n"
     ]
    }
   ],
   "source": [
    "print('F measure standard du label ' + str(label) + ' : ', F_measure_standard(Y_train_arr_tot[:,8], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que que le résulat de F measure est moyen. Cela est normal car un modèle type réseau de neuronne n'est pas forcément adapté, et on a pas cherché à l'optimiser / le tuner etc... L'objectif de cet exemple est surtout de mieux comprendre le problème et de mettre en évidence que pour entrainer un modèle prédiction d'un seul label, le temps est déjà conscéquent (1 seconde environ). Donc, si l'on doit créer un modèle par label, le temps d'entrainement sera très long : potentiellement plusieurs heures, voire jours dans le cadre d'un problème avec un m très élevé.\n",
    "\n",
    "Il est donc important d'utiliser un modèle adapté et optimisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model PLT : Probabilistic Label Tree :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un des modèles très souvent utilisé dans le cas d'XMLC est celui d'un PLT. Nous n'allons pas dans ce notebook essayer de créer nous même un PLT mais seulement essayer de comprendre le principe de ce modèle.\n",
    "\n",
    "Les PLT sont des arbres dont les feuilles correspondent aux labels du problème. La probabilité $\\eta(x,j)$ sera déterminée grâce au chemin reliant la racine de l'arbre jusqu'à la feuille correspondant au label j. <br>\n",
    "Le noeud racine est relié à plusieurs noeuds enfants, divisant ainsi l'espace des labels en des plusieurs sous-ensembles de labels. Puis les noeuds alors crées vont également avoir des noeuds enfants, ce qui va encore créer des sous-ensembles de labels plus petits. Ainsi, on pourra diviser l'ensemble de labels jusqu'à obtenir un seul label à chaque  feuilles.\n",
    "\n",
    "Chaque noeud est donc un classifieur qui aura pour objectif d'indiquer sur chacunes de ses branches la probabilité $\\eta$ que l'instance x qui pourcourt l'arbre ait un label positif au sein des sous-ensembles correspondants à ses enfants respectifs.\n",
    "\n",
    "On a alors : \n",
    "$$ \\eta(x,j) =  \\prod_{t \\in Path(j)}\\eta_T(x,t)$$\n",
    "où $t \\in Path(j)$ sont chacunes des branches reliant la racine à la feuille correspondante au label j.\n",
    "\n",
    "Nous n'allons pas étudier comment les classifieurs des noeuds fonctionnent, seulement essayer de comprendre pourquoi cette structure en arbre peut être intéressante. En effet, à priori, nous avons finalement crée plus que m classifieurs. C'est donc plus de classifieurs que ce que nous aurions fait avec une utilisation de plusieurs estimateurs binaires. Alors pourquoi ces arbres PLT sont intéressants ?\n",
    "\n",
    "Lorsque l'on étudie les différents labels probables d'une instance x en utilisant un PLT : on parcourt l'arbre, et on réalise la multiplication des probabilités présentes sur les branches. Assez rapidement, on va atteindre des noeuds dont la probabilité est très faible. Cela signifie que la probabilité que x ait un label dans le sous-ensemble de labels correspondant à ce noeud est très faible. Ainsi, l'étude de tous les noeuds issue de ce dernier n'est pas intéressante. Grâce à ce fonctionnement, si on se fixe un treshold de probabilité à partir duquel on considère que les labels à probabilité inférieure à cette valeur sont trop improbables, on peut réduire considérablement le nombre de classifieurs que l'on utilise. En pratique, avec un treshold raisonable on utilise moins de m classifieurs pour prédire les $\\hat{ \\eta}$ d'une instance. C'est pour cela que les PLT sont intéressants dans les problèmes d'XMLC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du modèle PLT de NapkinXC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie **napkinXC** nous permet de créer des modèles de prédictions PLT pour les datasets avec un nombre de classes très élevé. <br>\n",
    "Nous allons utiliser ces modèles tels quels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napkinxc.models import PLT\n",
    "from napkinxc.measures import precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = PLT(\"eurlex-model\") # Création d'un modèle type PLT\n",
    "plt.fit(X_train_napxinxc, Y_train_napxinxc) # Entrainement du modèle sur tout le train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ensuite utiliser ce modèle pour prédire les $\\eta$. <br>\n",
    "La librairie permet à l'utilisateur de préciser le treshold maximal à partir duquel il n'a plus besoin des prédictions. Par exemple, ci-dessous, si un label est estimé valable à moins de 20%, sa probabilité ne sera pas stoquée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'éxécution (secondes):  0.618349552154541\n",
      "[(1482, 0.6870196046520064), (1249, 0.6216845654287004), (446, 0.5513888687700165), (521, 0.4663520746994896), (1149, 0.20705874246714603)]\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "preds_proba = plt.predict_proba(X_train_napxinxc[:3500,:], threshold=0.2)\n",
    "print(\"Temps d'éxécution (secondes): \", time.time()-t)\n",
    "print(preds_proba[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc 4 labels pour lesquel la probabilité que l'instance $X[0]$  soit labélisé est supérieure à 0,2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on décide d'accéder à toutes les prédictions pour tous les labels (treshold de 0), les temps d'obtention sont beaucoup plus importants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'éxécution (secondes):  7.961107492446899\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "preds_proba = plt.predict_proba(X_train_napxinxc[:3500,:], threshold=0, top_k=0)\n",
    "print(\"Temps d'éxécution (secondes): \", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la liste preds_proba :  3500\n",
      "Taille de chaque item de preds_proba :  3993\n",
      "Extrait d'un item de preds_proba : \n",
      "[(1482, 0.6870196046520064), (1249, 0.6216845654287004), (446, 0.5513888687700165), (521, 0.4663520746994896), (1149, 0.20705874246714603), (1265, 0.16456291098252113), (591, 0.06715901876819737), (43, 0.030617532537065877), (201, 0.025018042184171134), (2223, 0.022965823915800654)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille de la liste preds_proba : \", len(preds_proba))\n",
    "print(\"Taille de chaque item de preds_proba : \", len(preds_proba[0]))\n",
    "print(\"Extrait d'un item de preds_proba : \")\n",
    "print(preds_proba[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont renvoyés comme un tableau où, chaque ligne correspond à une instance, et chaque colonne contient un doublet (label, probabilité). Les colonnes sont ordonnées par ordre de probabilité. Par exemple, en première colonne et première ligne se trouvent les informations du label le plus probable pour la première instance ainsi que sa probabiilité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce pré-tri est une spécificité de la librairie napkinXC. Pour la suite de notre étude nous allons utiliser les prédictions de probabilité pour tous les labels et nous allons considérer que les prédictions de base, ne sont pas classés. Nous allons donc re-trier ces prédictions dans un ordre plus intuitif, où la $j^{ème}$ colonne continent les valeurs de probabilités du label $j$.<br>\n",
    "Nous allons donc créer le tableau Y_proba qui contient les valeurs $\\eta$ du dataset obtenues par le classifieur. Sur la ligne i et la colonne j de Y_proba se trouve $\\eta_{i,j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Y_proba :  (3500, 3993)\n",
      "[[1.85232331e-05 4.28990773e-04 2.40944964e-05 ... 8.48217732e-06\n",
      "  7.28495341e-06 1.05442195e-05]\n",
      " [1.78664761e-05 1.14571933e-02 4.47722711e-04 ... 1.08242077e-05\n",
      "  5.82864890e-06 8.76953273e-06]\n",
      " [2.57057006e-05 1.59987784e-03 4.26426938e-05 ... 5.47150008e-05\n",
      "  2.71647065e-05 1.40854832e-05]\n",
      " ...\n",
      " [2.82723547e-06 7.07738799e-04 1.97562389e-06 ... 4.62966707e-07\n",
      "  2.99457979e-07 1.92104717e-06]\n",
      " [1.35577909e-05 4.13071840e-01 6.14580439e-04 ... 1.62272295e-05\n",
      "  1.23989849e-05 7.11139961e-06]\n",
      " [3.06055951e-06 1.90773925e-04 2.89767660e-06 ... 7.69885482e-06\n",
      "  9.90820122e-07 1.76674407e-06]]\n"
     ]
    }
   ],
   "source": [
    "Y_proba_sort_index = [ sorted(preds_proba[i], key=lambda r: r[0]) for i in range(len(preds_proba))]\n",
    "Y_proba = np.array([[prob for (ide,prob) in Y_proba_sort_index[i]]for i in range(len(Y_proba_sort_index))])\n",
    "print('Shape Y_proba : ', Y_proba.shape)\n",
    "print(Y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation des résultats obtenus :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant tester les prédictions de ce modèle NapkinXC en utilisant la fonction F_measure_macro définie plus haut.<br>\n",
    "Nous considèreront arbitrairement des tresholds à 0,3 pour chaque label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'éxécution (secondes):  2.1136634349823\n",
      "F_measure macro avec un threshold de 0.3 pour chaque label : 0.8123877095745675\n"
     ]
    }
   ],
   "source": [
    "thresh_list = np.ones(Y_proba.shape[1])*0.3\n",
    "t = time.time()\n",
    "preds = pred_from_proba_all_labels(Y_proba, thresh_list)\n",
    "print(\"Temps d'éxécution (secondes): \", time.time()-t)\n",
    "print(\"F_measure macro avec un threshold de 0.3 pour chaque label :\", F_measure_macro(Y_train_arr, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se rend compte que attribuer à chaque instance ses prédictions prend déjà quelques secondes. On se rend donc compte que lorsque que l'on cherchera à trouver le meilleur vecteur $\\mathbf{\\tau}$, il sera important d'essayer le moins possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V - Etape 2 : Trouver les thresholds $\\tau$ optimaux pour passer de $\\hat{\\eta}$ à y efficacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact de $\\tau$ sur la F-measure\n",
    "\n",
    "La F-measure est la métrique que l'on cherche à maximiser. La maximiser revient à maximiser les Standard F-measure de chaque label. Notre objectif est donc de trouver pour chaque label **j**, le bon threshold $\\mathbf{\\tau_j}$ qui permette de maximiser la F-measure standard de ce label.\n",
    "\n",
    "Regardons ensemble l'impact de ce treshold sur notre F-measure Macro : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F measure avec threshold de 0.1 :  0.7468708710520515\n",
      "F measure avec threshold de 0.3 :  0.8123877095745675\n",
      "F measure avec threshold de 0.5 :  0.6771001773087131\n"
     ]
    }
   ],
   "source": [
    "preds = pred_from_proba_all_labels(Y_proba, np.ones(Y_proba.shape[1])*0.05)\n",
    "print('F measure avec threshold de 0.1 : ', F_measure_macro(Y_train_arr, preds))\n",
    "preds = pred_from_proba_all_labels(Y_proba, np.ones(Y_proba.shape[1])*0.3)\n",
    "print('F measure avec threshold de 0.3 : ', F_measure_macro(Y_train_arr, preds))\n",
    "preds = pred_from_proba_all_labels(Y_proba, np.ones(Y_proba.shape[1])*0.5)\n",
    "print('F measure avec threshold de 0.5 : ', F_measure_macro(Y_train_arr, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remaque que en fonction du threshold que l'on applique la F-measure varie. Nous allons donc nous intéresser au différents moyen de trouver le threshold optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V-1 Méthodes \"de base\" pour optenir les $\\mathbf{\\tau}$ optimaux :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode 1, Méthode naïve : Essaie de plusieurs thresholds avec un pas :\n",
    "On peut naïvement chercher le threshold donnant la meilleure F-Measure entre 0 et 1 avec un pas donné. Créons une fonction réalisant cela pour un label :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_threshold_optimisation_one_label(y_true, proba_pred, pas):\n",
    "    best_f_meas = 0\n",
    "    best_thresh = 1\n",
    "    for i in np.arange(0,1,pas):\n",
    "        f_meas_tmp = F_measure_standard(y_true, pred_from_proba_one_label(proba_pred, i))\n",
    "        if f_meas_tmp > best_f_meas:\n",
    "            best_thresh = i\n",
    "            best_f_meas = f_meas_tmp\n",
    "    return (best_f_meas, best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La complexité de cette fonction est : $\\frac{1}{pas}\\times n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9534883720930233, 0.2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 4\n",
    "naive_threshold_optimisation_one_label(Y_train_arr[:,label], Y_proba[:,label], 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons alors réaliser cela pour tous les labels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  /  3993\n",
      "1000  /  3993\n",
      "2000  /  3993\n",
      "3000  /  3993\n",
      "Temps d'éxécution (secondes):  29.318833827972412\n",
      "Liste de threshold [0.1 0.3 1.  ... 1.  1.  1. ]\n"
     ]
    }
   ],
   "source": [
    "def give_all_thresholds_naive_solution(y_prob, y_true):\n",
    "    t = time.time()\n",
    "    threshs = np.zeros(Y_proba.shape[1])\n",
    "    for i in range(len(threshs)):\n",
    "        if i%1000==0:\n",
    "            print(i, ' / ', len(threshs))\n",
    "        threshs[i] = naive_threshold_optimisation_one_label(y_true[:,i], y_prob[:,i], 0.1)[1]\n",
    "    print(\"Temps d'éxécution (secondes): \", time.time()-t)\n",
    "    return threshs\n",
    "thresholds = give_all_thresholds_naive_solution(Y_proba, Y_train_arr)\n",
    "print(\"Liste de threshold\", thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La complexité de cette fonction est de $\\frac{1}{pas} \\times n \\times m$ et le temps d'éxécution est long (quelques dizaines de secondes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F measure macro :  0.861175276424519\n"
     ]
    }
   ],
   "source": [
    "preds = pred_from_proba_all_labels(Y_proba, thresholds)\n",
    "print('F measure macro : ', F_measure_macro(Y_train_arr, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode 2, Méthode \"solution exacte\" (mais de grande complexité) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour être certain d'avoir les $\\tau_j$ optimaux, on peut aussi donner à $\\tau_j$ itérativemement toutes les valeurs différentes prises par les $\\eta_j$, et voir la F-measure la plus élevée.\n",
    "\n",
    "Si l'on réalise cela pour un label : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_threshold_solution(y_true, proba_pred):\n",
    "    best_f_meas = 0\n",
    "    best_thresh = 1\n",
    "    for p in proba_pred:\n",
    "        f_meas_tmp = F_measure_standard(y_true, pred_from_proba_one_label(proba_pred, p))\n",
    "        if f_meas_tmp > best_f_meas:\n",
    "            best_thresh = p\n",
    "            best_f_meas = f_meas_tmp\n",
    "    return (best_f_meas, best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La complexité de cette fonction est $n^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9534883720930233, 0.189021635672496)\n",
      "Temps d'éxécution (secondes):  2.5765597820281982\n"
     ]
    }
   ],
   "source": [
    "label = 4\n",
    "t = time.time()\n",
    "print(exact_threshold_solution(Y_train_arr[:,label], Y_proba[:,label]))\n",
    "print(\"Temps d'éxécution (secondes): \", time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un seul label, le temps d'éxécution est déjà de l'ordre de la seconde avec un n relativement petit (3500). Cette solution semble inenvisageable pour trouver les thresholds de tous les labels (4000 labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode 3, Test sur les valeurs de $\\eta$ au dessus d'un certain threshold :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cause du temps d'éxécution de la solution exacte, on ne va plus tester toutes les valeurs de $\\eta$, mais seulement les valeurs de $\\eta$ qui sont les plus élevées. Pour cela nous allons donc auparavant trier la liste les prédiction $\\eta$, puis tester toutes ces valeurs pour $\\tau_j$ juqu'à une certaine valeur minimale $\\kappa_j$.\n",
    "\n",
    "La fonction de tri initiale est (pour chaque label) de complexité $n \\log{n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_threshold_solution(y_true, proba_pred, k):\n",
    "    best_f_meas = 0\n",
    "    best_thresh = 1\n",
    "    sorted_pred = proba_pred.copy()\n",
    "    sorted_pred = np.sort(sorted_pred)\n",
    "    if len(proba_pred)>0:  \n",
    "        i= 1\n",
    "        while (i< len(sorted_pred)) & (sorted_pred[-i]>k):\n",
    "            p = sorted_pred[-i]\n",
    "            f_meas_tmp = F_measure_standard(y_true, pred_from_proba_one_label(proba_pred, p))\n",
    "            if f_meas_tmp > best_f_meas:\n",
    "                best_thresh = p\n",
    "                best_f_meas = f_meas_tmp\n",
    "            i += 1\n",
    "        return (best_f_meas, best_thresh)\n",
    "    else:\n",
    "        if len(y_true)>0:\n",
    "            return (0,1)\n",
    "        else:\n",
    "            return (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9534883720930233, 0.189021635672496)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=4\n",
    "sort_threshold_solution(Y_train_arr[:,label], Y_proba[:,label], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on prend un threshold initial $\\kappa_j$ assez petit, cette méthode à plus de chances de donnef la solution exacte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  /  3993\n",
      "1000  /  3993\n",
      "2000  /  3993\n",
      "3000  /  3993\n",
      "Temps d'éxécution (secondes):  26.246495723724365\n",
      "Liste de threshold [0.44939146 0.30559412 1.         ... 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "def give_all_thresholds_sort_solution(y_proba, y_true, k):\n",
    "    t = time.time()\n",
    "    treshs = np.zeros(y_proba.shape[1])\n",
    "    for i in range(len(thresholds)):\n",
    "        if i%1000==0:\n",
    "            print(i, ' / ', len(treshs))\n",
    "        treshs[i] = sort_threshold_solution(y_true[:,i], y_proba[:,i], k)[1]\n",
    "    print(\"Temps d'éxécution (secondes): \", time.time()-t)\n",
    "    return treshs\n",
    "thresholds = give_all_thresholds_sort_solution(Y_proba, Y_train_arr, 0.05)\n",
    "print(\"Liste de threshold\", thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F measure macro :  0.8887356492222076\n"
     ]
    }
   ],
   "source": [
    "preds = pred_from_proba_all_labels(Y_proba, thresholds)\n",
    "print('F measure macro : ', F_measure_macro(Y_train_arr, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que l'on obtient des meilleurs résultats qu'avec la méthode naïve ou l'on teste les thresholds avec un pas donné. D'un point de vue compléxité, cela dépend la répartition des probabilités du classifieur. En pratique sur cet exemple, le temps d'éxécution est du même ordre de grandeur que pour la méthode naïve. <br>\n",
    "En revanche le threshold initial de tri a beaucoup d'importance. On peut remarquer que si on prend un threshold de 0.1 au lieu de 0.05 comme au dessus, les résultats sont moins bons mais le temps d'éxécution est plus court."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  /  3993\n",
      "1000  /  3993\n",
      "2000  /  3993\n",
      "3000  /  3993\n",
      "Temps d'éxécution (secondes):  17.701774835586548\n",
      "F measure macro :  0.8449454911971181\n"
     ]
    }
   ],
   "source": [
    "thresholds = give_all_thresholds_sort_solution(Y_proba, Y_train_arr, 0.1)\n",
    "preds = pred_from_proba_all_labels(Y_proba, thresholds)\n",
    "print('F measure macro : ', F_measure_macro(Y_train_arr, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V-2 Méthodes optimisées pour optenir les $\\mathbf{\\tau}$ optimaux :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode STO : Search-based trehsold optimization :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de la méthode STO est encore une fois de déterminer les meilleurs thresholds $\\tau$, mais cette fois avec un complexité moindre par rapport aux méthodes basique que l'on vient de voir. La méthode STO est basée sur le concepte de SPE (sparse probability estimates). Ces SPE sont en fait un sous ensemble des $\\eta$ dans lequel on a gardé seulement les probabilités $\\eta$ suffisamment grande. On considère donc que ce sous ensemble suffira à déterminer les thresholds $\\tau$ optimaux. Travailler seulement sur les SPE réduira grandement le temps d'éxécution de nos algorithmes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les SPE d'une instance **x** que l'on va utiliser sont : \n",
    "\n",
    "$$ \\hat{s}_{\\mathbf{\\kappa}}(\\mathbf{x}) = \\{ \\hat{\\eta}(\\mathbf{x},j) : j \\in \\hat{\\ell_{\\kappa}}(\\mathbf{x}) \\}$$\n",
    "\n",
    "$$\\hat{\\ell_{\\kappa}}(\\mathbf{x}) = \\{ j \\in [m] : \\hat{\\eta}(\\mathbf{x},j) > \\kappa_{j}    \\}  $$\n",
    "\n",
    "où $\\mathbf{\\kappa} = (\\kappa_1, ... , \\kappa_m) \\in  [0, 1]^m$ et $\\kappa_j$ est le threshold pour le label j à partir duquel on utilisera la donnée $\\hat{\\eta}_(x,j)$ pour trouver le thresholds $\\tau_j$ optimal. Bien sûr, les thresholds $\\kappa_j$ doivent être inférieurs aux thresholds $\\tau_j$ à déterminer. Pour simplifier l'algorithmes on prendra le même thresholds $\\kappa$ pour tout le monde : $\\kappa_1 = ... = \\kappa_m = \\kappa$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée de l'agorithme de STO est dans un premier temps de trouver les différents $\\hat{s}_{\\mathbf{\\kappa}}(\\mathbf{x})$ et $\\hat{\\ell_{\\kappa}}(\\mathbf{x})$ pour chaque instance, puis, comme on a déjà fait, tester ces chacuns des $\\eta(x,j)$ retenus comme threshold $\\tau_j$ et calculer la F_measure correspondante mais seulement sur les données que l'on aura selectionné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_lkx_skx(proba_x, list_k):\n",
    "    lkx = []\n",
    "    skx = []\n",
    "    for j in range(len(proba_x)):\n",
    "        proba_tmp = proba_x[j]\n",
    "        if proba_tmp > list_k[j] :\n",
    "            lkx.append(j)\n",
    "            skx.append(proba_tmp)\n",
    "    return lkx, skx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape 1 : Lister les instances à utiliser pour chaque label :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chacun de ces éléments est une ensemble d'instances qui répertorient les instances qui seront utilisés pour le calcul de threshold.\n",
    "def sto_give_sets(y_prob, list_k):\n",
    "    t = time.time()\n",
    "    sets_j = []\n",
    "    for j in range(y_prob.shape[1]):\n",
    "        sets_j.append([])\n",
    "    for i in range(y_prob.shape[0]):\n",
    "        lkx_tmp, skx_tmp = give_lkx_skx(y_prob[i], list_k)\n",
    "        for lab in lkx_tmp:\n",
    "            sets_j[lab].append(i)\n",
    "    print(\"Temps d'éxécution étape 1 (secondes): \", time.time()-t)\n",
    "    return sets_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape 2 : Déterminer les thresholds optimaux à partir de ces instances :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sto_thresholds_from_sets(sets, y_prob, y_true):\n",
    "    t = time.time()\n",
    "    treshs = np.zeros(len(sets))\n",
    "    for j in range(len(sets)):\n",
    "        probas_j = np.take(y_prob[:,j], sets[j])\n",
    "        y_j = np.take(y_true[:,j], sets[j])\n",
    "        _, treshs[j] = exact_threshold_solution(y_j,probas_j)\n",
    "    print(\"Temps d'éxécution étape 2 (secondes): \", time.time()-t)\n",
    "    return treshs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction avec les deux étapes combinées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sto_both_steps(y_prob, y_true, list_k):\n",
    "    sets_j = sto_give_sets(y_prob, 0.05*np.ones(Y_proba.shape[1]))\n",
    "    return(sto_thresholds_from_sets(sets_j, y_prob, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'éxécution étape 1 (secondes):  4.641836643218994\n",
      "Temps d'éxécution étape 2 (secondes):  2.0305562019348145\n",
      "F measure macro :  0.8886988682894431\n"
     ]
    }
   ],
   "source": [
    "thresholds = sto_both_steps(Y_proba, Y_train_arr, 0.05*np.ones(Y_proba.shape[1]))\n",
    "preds = pred_from_proba_all_labels(Y_proba, thresholds)\n",
    "print('F measure macro : ', F_measure_macro(Y_train_arr, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le réultat est similaire à ce que l'on a pu obtenir pour la méthode 3 ce qui est normal puisque les calculs réalisés ont la même logique mathématique. En revance, on a un temps global d'éxécution d'environ 6 secondes. Cela est 4 fois inférieur au temps d'éxécution que l'on avait avec la méthode 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode OFO (Online F-measure Optimization) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons étudier une dernière méthode qui permet de trouver les threshold optimaux avec un \"faible\" temps déxécution . Nous allons pour cela créer un algorithme où le threshold $\\tau$ va évoluer au fur et à mesure que l'on explore le dataset.\n",
    "\n",
    "On a pour le label j :\n",
    "$$ F_{i,j} =  \\frac{2 \\sum_{p=1}^i y_{p,j}\\hat{y}_{p,j}}{\\sum_{p=1}^i y_{p,j} + \\sum_{p=1}^j \\hat{y}_{p,j}} =  \\frac{2 a_{i,j}}{b_{i,j}}$$\n",
    "avec : \n",
    "$$ a_{i,j} = \\sum_{p=1}^i y_{p,j}\\hat{y}_{p,j}$$,\n",
    "    print(sets_j) $$b_{i,j} = \\sum_{p=1}^i y_{p,j} + \\sum_{p=1}^j \\hat{y}_{p,j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme OFO fixe la valeur du threshold à : $$\\tau_{i,j} = \\frac{a_{i-1,j}}{b_{i-1,j}}$$\n",
    "\n",
    "L'idée de l'agorithme est de parcourir le dataset et de faire évoluer la valeur de $\\tau_{i,j}$ graĉe aux relations suivantes : \n",
    "\n",
    "$$ a_{i,j} = a_{i-1,j} + y_{i,j} \\times \\hat{y}_{i,j}$$\n",
    "$$ b_{i,j} = b_{i-1,j} + y_{i,j} + \\hat{y}_{i,j}$$\n",
    "\n",
    "où $\\hat{y}_{i,j}$ est calculé grace à $\\tau_{i-1,j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut se demander légitimement pourquoi $\\tau_{i,j}$ est fixé à $\\frac{a_{i-1,j}}{b_{i-1,j}}$. Cette condition vient de l'étude [Zhao et al, 2013]. Il y est expliqué que lorsque l'on connait les probabilités réelles $\\eta$ de tout le dataset, nous avons la relation suivante entre le $\\tau$ optimal $\\tau^*$ et la F-measure correspondante : \n",
    "$$ F^* = F(\\tau^*) = 2\\tau^*$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons maintenant de coder cette méthode. On initialisera les premier $\\tau_j$ à 0,4. Pour cela les $a_{0,j}$ et $ b_{0,j}$ seront initialisés à 10 et 4 respectivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFO(y_prob, y_true, a_list, b_list):\n",
    "    t = time.time()\n",
    "    n, m = y_prob.shape\n",
    "    list_thresh = [a/b for (a,b) in zip(a_list, b_list)] #Initialisation des thresholds avec les valeurs initiales de a et b\n",
    "    for i in range(n):\n",
    "        lkx, _ = give_lkx_skx(y_prob[i], list_thresh) # Les labels de x selon les predictions de probabilités et threshold_i\n",
    "        true_label_of_x = np.where(y_true[i] == 1) # Les vrais labels de x\n",
    "        lkx = set(lkx)\n",
    "        true_label_of_x = set(true_label_of_x[0])\n",
    "        for j in lkx.union(true_label_of_x):\n",
    "            a_list[j] += len(lkx.intersection(true_label_of_x))\n",
    "            b_list[j] += len(lkx) + len(true_label_of_x)\n",
    "            list_thresh[j] = a_list[j]/b_list[j]\n",
    "    print(\"Temps d'éxécution étape 2 (secondes): \", time.time()-t)\n",
    "    return list_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'éxécution étape 2 (secondes):  2.7430944442749023\n"
     ]
    }
   ],
   "source": [
    "a_l = 4*np.ones(Y_proba.shape[1])\n",
    "b_l = 10*np.ones(Y_proba.shape[1])\n",
    "thresholds = OFO(Y_proba, Y_train_arr, a_l, b_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F measure macro :  0.7687405567711114\n"
     ]
    }
   ],
   "source": [
    "preds = pred_from_proba_all_labels(Y_proba, thresholds)\n",
    "print('F measure macro : ', F_measure_macro(Y_train_arr, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que la F_measure est moins bonne qu'avec les autres méthodes, ce qui peut normal puisque ces dernière sont des dolutions plus \"exactes\". En revanche le temps d'éxécution est plus faible (divisé par 2 environ)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
